# computer_vision

## Papers

### To Read
#### Deep Learning Generic
* [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf) , ICML, 2015
* [ LSTM: A search space odyssey](https://arxiv.org/pdf/1503.04069.pdf) ,IEEE-TNNLS, 2016
* [On the importance of initialization and momentum in deep learning](http://proceedings.mlr.press/v28/sutskever13.pdf), ICML, 2013
* [Net2net: Accelerating learning via knowledge transfer](https://arxiv.org/pdf/1511.05641.pdf), ICLR, 2016
* [Network morphism](http://proceedings.mlr.press/v48/wei16.pdf), ICML, 2016
* [Intriguing properties of neural networks](https://arxiv.org/pdf/1312.6199.pdf), ICLR, 2014
* [Dynamic Routing Between Capsules](https://arxiv.org/pdf/1710.09829.pdf), NIPS, 2017
#### Generative Models for Vision
* [Generative adversarial nets](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf), NIPS, 2014 [GAN]
* [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434.pdf), ICLR, 2016 [DCGAN]
* [Conditional image generation with pixelcnn decoders](http://papers.nips.cc/paper/6527-conditional-image-generation-with-pixelcnn-decoders.pdf), NIPS,2016
* [PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modifications](https://arxiv.org/pdf/1701.05517.pdf), ICLR, 2016
* [Pixel recurrent neural networks](https://arxiv.org/pdf/1601.06759.pdf), ICML, 2016
* [InfoGAN](https://arxiv.org/pdf/1606.03657.pdf) NIPS,2016
* [Image Style Transfer Using Convolutional Neural Networks](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf) ,CVPR, 2016 [ Neural Style Transfer]
* [Real-Time Single Image and Video Super-Resolution Using an Efficient
Sub-Pixel Convolutional Neural Network](https://arxiv.org/pdf/1609.05158.pdf), CVPR, 2016
* [Improved Techniques for Training GAN](https://arxiv.org/pdf/1606.03498.pdf), NIPS, 2016
* [Wasserstein GAN](https://arxiv.org/abs/1701.07875)
* [Improved Training of Wasserstein GANs](https://arxiv.org/pdf/1704.00028.pdf), NIPS, 2017
* [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434.pdf), ICLR, 2016
* [Least Squares Generative Adversarial Networks](https://arxiv.org/pdf/1611.04076.pdf), ICCV, 2017


#### Object Detection/Recognition/Segmentation
* [Scalable Object Detection Using Deep Neural Networks](https://arxiv.org/pdf/1312.2249.pdf), CVPR, 2014
* [Fast R-CNN](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Girshick_Fast_R-CNN_ICCV_2015_paper.pdf) , ICCV, 2015
* [Faster R-CNN: Towards real-time object detection with region proposal networks](http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf), NIPS, 2015
* [Mask R-CNN](https://arxiv.org/pdf/1703.06870.pdf), ICCV, 2017
* [You only look once: Unified, real-time object detection](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf), CVPR, 2016
* [Rich feature hierarchies for accurate object detection and semantic segmentation](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf), CVPR, 2014
* [Segmentation as selective search for object recognition](https://www.koen.me/research/pub/vandesande-iccv2011.pdf), ICCV, 2011
* [SSD: Single shot multibox detector](https://arxiv.org/pdf/1512.02325.pdf), ECCV, 2016
* [Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps](https://arxiv.org/pdf/1312.6034.pdf), CVPR, 2013
* [DenseCap: Fully Convolutional Localization Networks for Dense Captioning](https://arxiv.org/pdf/1511.07571.pdf), CVPR, 2016

### Read 
#### Deep Learning Generic
* [Network In Network](https://arxiv.org/pdf/1312.4400.pdf), ICLR, 2014
* [Striving for Simplicity: The All Convolutional Net](https://arxiv.org/pdf/1412.6806.pdf), ICLR, 2014
* [Deep Learning Using Linear Support Vector Machines](https://arxiv.org/pdf/1306.0239.pdf)

#### ImageNet Competition Winners
* [Imagenet classification with deep convolutional neural networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), NIPS,2014, [AlexNet]
* [Going Deeper with Convolutions](https://arxiv.org/pdf/1409.4842.pdf), CVPR, 2015 [GoogLeNet]
* [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf), CVPR, 2016 [ResNet]
* [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556v6), ICLR, 2015 [VGGNet]
* [Visualizing and Understanding Convolutional Networks](https://arxiv.org/pdf/1311.2901.pdf) ECCV, 2014 [ZfNet]
#### General
* [Domingos, Pedro M. “A Few Useful Things to Know about Machine Learning.”](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf) Communications of The ACM, 2012
#### Traditional Vision

* [Tomasi, and Jianbo Shi. “Good Features to Track.”](http://ntucsu.csie.ntu.edu.tw/~b92025/paper/shi-tomasi-good-features-cvpr1994.pdf), CVPR, 1994
    <details>
        The papers addresses three issues in image tracking in an image sequence.First they demonstrate that pure transaltional models are not measures to measure dissimilarity in features across frames. Affine image changes perform decently to measure dissimilarity. Secondly they propose a stable numerical method using Newton-Raphson minimization procedure to track features.Thirdly, they propose a feature selection criterion based on tracker's accuracy. This is an old paper and has been superseeded. 
    </details>
* [Mikolajczyk, Krystian, and Cordelia Schmid. “A Performance Evaluation of Local Descriptors.”](https://www.robots.ox.ac.uk/~vgg/research/affine/det_eval_files/mikolajczyk_pami2004.pdf), PAML, 2005
    <details>
        This work analyses various descriptors and describes the performance wrt the region on interest.  The evaluation criteria they used was recall and precision. They carried out tests for various image transformations. The descriptors they comapred include SIFT, spin images, complex filter, moment invariants etc. 
    </details>
* [Lowe, David G. “Distinctive Image Features from Scale-Invariant Keypoints.” ](http://www-inst.eecs.berkeley.edu/~ee225b/fa12/readings/sift-lowe.pdf), 2004
    <details>
     This papers presents a method to extract features from images which are robust to image scale and rotation, affine distortion, change in 3d viewpoint etc. The major parts of the paper are :
     <ul>
     <li> Identify points of interests by using a difference of gaussian function.
     <li> Filter points based on location, scale and ratio of principal curvatures.
     <li> Assign orientation to each point based on direction of local image gradients.
     <li> Determine the features by computing image gradients relative to orientation and weigh them by using a gaussain function. Create a gradient histogram with each bar representing the magnitude of gradients in a particular direction.
     </ul>
    </details>
* [Indexing based on scale invariant interest points](https://hal.inria.fr/inria-00548276/document)
* [Visual Tracking with Online Multiple Instance Learning](https://vision.cornell.edu/se3/wp-content/uploads/2014/09/0fcfd5086e4e9dd86c000000.pdf), CVPR, 2009
* [Mean shift: a robust approach toward feature space analysis](http://ieeexplore.ieee.org/abstract/document/1000236/)
    <details>
        This paper gives an approach to analyse large dimensioanl feature spaces. The main idea used is of the density estimation using kernels. So basically, the features are projected into a d dimensional space and density function is defined over all the projected points. Mean shift procedure(basically gradient descent on density function) is used to find extrema's of the density estimate. This processed feature space is used for discontinuity preserving smoothing and segmentation problems.
    </details>
* [EpicFlow: Edge-preserving interpolation of correspondences for optical flow](https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Revaud_EpicFlow_Edge-Preserving_Interpolation_2015_CVPR_paper.pdf), CVPR 2015
* [Torr, Philip H. S., et al. “Struck: Structured Output Tracking with Kernels.](https://ora.ox.ac.uk/objects/uuid:0eb1b105-81f3-4a79-a503-f492994cc80a/datastreams/ATTACHMENT01), ICCV, 2011
* [Mikolajczyk, Krystian, et al. “Tracking-Learning-Detection.”](http://ieeexplore.ieee.org/document/6104061/), PAML, 2012

## Books

* Computer Vision: Algorithms and Applications , Richard Szeliski , [Link](http://szeliski.org/Book/)
* Computer Vision, A Modern Approach 2nd Edition , Forsyth and Ponce.
 
 ## Workshops/Tutorials
 * [NIPS 2016 Adversarial Training](https://sites.google.com/site/nips2016adversarial/)
    * [NIPS 2016 Tutorial: Generative Adversarial Networks](https://arxiv.org/pdf/1701.00160.pdf)
